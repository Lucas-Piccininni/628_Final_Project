{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing audio...\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "(1, 16000)\n",
      "up\n",
      "Stopping audio capture...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for audio capture\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK_SIZE = 16000\n",
    "\n",
    "# Threshold for audio volume\n",
    "THRESHOLD = 2048  # Adjust this value according to your needs\n",
    "\n",
    "label_names = ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open a stream for audio capture\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "print(\"Capturing audio...\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the SavedModel\n",
    "model = tf.saved_model.load(\"saved\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Read audio data from the stream\n",
    "        data = stream.read(CHUNK_SIZE)\n",
    "        \n",
    "        # Convert the data to numpy array for further processing\n",
    "        audio_data = np.frombuffer(data, dtype=np.float16)\n",
    "        audio_data = tf.convert_to_tensor(audio_data, dtype=tf.float32)\n",
    "        audio_data = np.expand_dims(audio_data, axis=0)\n",
    "        \n",
    "        print(audio_data.shape)\n",
    "        \n",
    "        # Check if audio data is not empty\n",
    "        if len(audio_data) > 0:\n",
    "            y_pred = model(audio_data)\n",
    "            y_pred = y_pred['class_ids'].numpy()[0]\n",
    "            \n",
    "            print(label_names[y_pred])\n",
    "\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping audio capture...\")\n",
    "    # Close the stream and terminate PyAudio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
